{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "### นายพัสกร โตวตระกูล รหัสนักศึกษา 590610644\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn import  datasets\n",
    "\n",
    "audit = pd.read_csv('audit_data/audit_risk.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## รายละเอียดข้อมูลที่ใช้ในการทดลอง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Score_B.1</th>\n",
       "      <th>...</th>\n",
       "      <th>RiSk_E</th>\n",
       "      <th>History</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Risk_F</th>\n",
       "      <th>Score</th>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>Detection_Risk</th>\n",
       "      <th>Audit_Risk</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.0</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.184536</td>\n",
       "      <td>2.450194</td>\n",
       "      <td>0.351289</td>\n",
       "      <td>1.351029</td>\n",
       "      <td>10.799988</td>\n",
       "      <td>0.313144</td>\n",
       "      <td>6.334008</td>\n",
       "      <td>13.218481</td>\n",
       "      <td>5.067655</td>\n",
       "      <td>0.223711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519072</td>\n",
       "      <td>0.104381</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.053608</td>\n",
       "      <td>2.702577</td>\n",
       "      <td>17.680612</td>\n",
       "      <td>0.572680</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.168158</td>\n",
       "      <td>0.393041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.319017</td>\n",
       "      <td>5.678870</td>\n",
       "      <td>0.174055</td>\n",
       "      <td>3.440447</td>\n",
       "      <td>50.083624</td>\n",
       "      <td>0.169804</td>\n",
       "      <td>30.072845</td>\n",
       "      <td>51.312829</td>\n",
       "      <td>0.264449</td>\n",
       "      <td>0.080352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290312</td>\n",
       "      <td>0.531031</td>\n",
       "      <td>0.067987</td>\n",
       "      <td>0.305835</td>\n",
       "      <td>0.858923</td>\n",
       "      <td>54.740244</td>\n",
       "      <td>0.444581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.667494</td>\n",
       "      <td>0.488741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.370000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.583500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.316700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.890000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.214000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.555600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.570000</td>\n",
       "      <td>2.480000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.840500</td>\n",
       "      <td>7.707500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>10.663500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.249900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.850000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1264.630000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>758.778000</td>\n",
       "      <td>1268.910000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>801.262000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>961.514400</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sector_score      PARA_A     Score_A      Risk_A       PARA_B  \\\n",
       "count    776.000000  776.000000  776.000000  776.000000   776.000000   \n",
       "mean      20.184536    2.450194    0.351289    1.351029    10.799988   \n",
       "std       24.319017    5.678870    0.174055    3.440447    50.083624   \n",
       "min        1.850000    0.000000    0.200000    0.000000     0.000000   \n",
       "25%        2.370000    0.210000    0.200000    0.042000     0.000000   \n",
       "50%        3.890000    0.875000    0.200000    0.175000     0.405000   \n",
       "75%       55.570000    2.480000    0.600000    1.488000     4.160000   \n",
       "max       59.850000   85.000000    0.600000   51.000000  1264.630000   \n",
       "\n",
       "          Score_B      Risk_B        TOTAL     numbers   Score_B.1  \\\n",
       "count  776.000000  776.000000   776.000000  776.000000  776.000000   \n",
       "mean     0.313144    6.334008    13.218481    5.067655    0.223711   \n",
       "std      0.169804   30.072845    51.312829    0.264449    0.080352   \n",
       "min      0.200000    0.000000     0.000000    5.000000    0.200000   \n",
       "25%      0.200000    0.000000     0.537500    5.000000    0.200000   \n",
       "50%      0.200000    0.081000     1.370000    5.000000    0.200000   \n",
       "75%      0.400000    1.840500     7.707500    5.000000    0.200000   \n",
       "max      0.600000  758.778000  1268.910000    9.000000    0.600000   \n",
       "\n",
       "          ...          RiSk_E     History        Prob      Risk_F       Score  \\\n",
       "count     ...      776.000000  776.000000  776.000000  776.000000  776.000000   \n",
       "mean      ...        0.519072    0.104381    0.216753    0.053608    2.702577   \n",
       "std       ...        0.290312    0.531031    0.067987    0.305835    0.858923   \n",
       "min       ...        0.400000    0.000000    0.200000    0.000000    2.000000   \n",
       "25%       ...        0.400000    0.000000    0.200000    0.000000    2.000000   \n",
       "50%       ...        0.400000    0.000000    0.200000    0.000000    2.400000   \n",
       "75%       ...        0.400000    0.000000    0.200000    0.000000    3.250000   \n",
       "max       ...        2.400000    9.000000    0.600000    5.400000    5.200000   \n",
       "\n",
       "       Inherent_Risk  CONTROL_RISK  Detection_Risk  Audit_Risk        Risk  \n",
       "count     776.000000    776.000000           776.0  776.000000  776.000000  \n",
       "mean       17.680612      0.572680             0.5    7.168158    0.393041  \n",
       "std        54.740244      0.444581             0.0   38.667494    0.488741  \n",
       "min         1.400000      0.400000             0.5    0.280000    0.000000  \n",
       "25%         1.583500      0.400000             0.5    0.316700    0.000000  \n",
       "50%         2.214000      0.400000             0.5    0.555600    0.000000  \n",
       "75%        10.663500      0.400000             0.5    3.249900    1.000000  \n",
       "max       801.262000      5.800000             0.5  961.514400    1.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sector_score', 'LOCATION_ID', 'PARA_A', 'Score_A', 'Risk_A', 'PARA_B',\n",
      "       'Score_B', 'Risk_B', 'TOTAL', 'numbers', 'Score_B.1', 'Risk_C',\n",
      "       'Money_Value', 'Score_MV', 'Risk_D', 'District_Loss', 'PROB', 'RiSk_E',\n",
      "       'History', 'Prob', 'Risk_F', 'Score', 'Inherent_Risk', 'CONTROL_RISK',\n",
      "       'Detection_Risk', 'Audit_Risk', 'Risk'],\n",
      "      dtype='object')\n",
      "attributes = 26\n"
     ]
    }
   ],
   "source": [
    "print(audit.columns)\n",
    "print('attributes =', len(audit.columns) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Audit Data เป็นข้อมูลเพื่อการ Classification มี 2 คลาส (Risk = 0 หรือ 1) \n",
    "มีทั้งหมด 26 attributes จำนวน 777 instances \n",
    "\n",
    "ข้อมูลเป็นรูปแบบ จำนวนจริง มี missing value เผยแพร่ตั้งแต่ 2018-07-14 \n",
    "\n",
    "**นำรายละเอียดข้อมูลมากจาก** \n",
    "\n",
    "   UCI Machine Learning Repository [https://archive.ics.uci.edu/ml/datasets/Audit+Data]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. วิเคราะห์ชนิดของข้อมูลและความสำคัญของแต่ละข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 776 entries, 0 to 775\n",
      "Data columns (total 27 columns):\n",
      "Sector_score      776 non-null float64\n",
      "LOCATION_ID       776 non-null object\n",
      "PARA_A            776 non-null float64\n",
      "Score_A           776 non-null float64\n",
      "Risk_A            776 non-null float64\n",
      "PARA_B            776 non-null float64\n",
      "Score_B           776 non-null float64\n",
      "Risk_B            776 non-null float64\n",
      "TOTAL             776 non-null float64\n",
      "numbers           776 non-null float64\n",
      "Score_B.1         776 non-null float64\n",
      "Risk_C            776 non-null float64\n",
      "Money_Value       775 non-null float64\n",
      "Score_MV          776 non-null float64\n",
      "Risk_D            776 non-null float64\n",
      "District_Loss     776 non-null int64\n",
      "PROB              776 non-null float64\n",
      "RiSk_E            776 non-null float64\n",
      "History           776 non-null int64\n",
      "Prob              776 non-null float64\n",
      "Risk_F            776 non-null float64\n",
      "Score             776 non-null float64\n",
      "Inherent_Risk     776 non-null float64\n",
      "CONTROL_RISK      776 non-null float64\n",
      "Detection_Risk    776 non-null float64\n",
      "Audit_Risk        776 non-null float64\n",
      "Risk              776 non-null int64\n",
      "dtypes: float64(23), int64(3), object(1)\n",
      "memory usage: 163.8+ KB\n"
     ]
    }
   ],
   "source": [
    "audit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>...</th>\n",
       "      <th>RiSk_E</th>\n",
       "      <th>History</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Risk_F</th>\n",
       "      <th>Score</th>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>Detection_Risk</th>\n",
       "      <th>Audit_Risk</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>23</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.508</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>6.68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.574</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.966</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.554</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.548</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.480</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>17.530</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.5060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.416</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sector_score LOCATION_ID  PARA_A  Score_A  Risk_A  PARA_B  Score_B  Risk_B  \\\n",
       "0          3.89          23    4.18      0.6   2.508    2.50      0.2   0.500   \n",
       "1          3.89           6    0.00      0.2   0.000    4.83      0.2   0.966   \n",
       "2          3.89           6    0.51      0.2   0.102    0.23      0.2   0.046   \n",
       "3          3.89           6    0.00      0.2   0.000   10.80      0.6   6.480   \n",
       "4          3.89           6    0.00      0.2   0.000    0.08      0.2   0.016   \n",
       "\n",
       "   TOTAL  numbers  ...   RiSk_E  History  Prob  Risk_F  Score  Inherent_Risk  \\\n",
       "0   6.68      5.0  ...      0.4        0   0.2     0.0    2.4          8.574   \n",
       "1   4.83      5.0  ...      0.4        0   0.2     0.0    2.0          2.554   \n",
       "2   0.74      5.0  ...      0.4        0   0.2     0.0    2.0          1.548   \n",
       "3  10.80      6.0  ...      0.4        0   0.2     0.0    4.4         17.530   \n",
       "4   0.08      5.0  ...      0.4        0   0.2     0.0    2.0          1.416   \n",
       "\n",
       "   CONTROL_RISK  Detection_Risk  Audit_Risk  Risk  \n",
       "0           0.4             0.5      1.7148     1  \n",
       "1           0.4             0.5      0.5108     0  \n",
       "2           0.4             0.5      0.3096     0  \n",
       "3           0.4             0.5      3.5060     1  \n",
       "4           0.4             0.5      0.2832     0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "พบว่า ข้อมูลเกือบทุก attributes อยู่ในรูปแบบของ number หมดแล้ว\n",
    "\n",
    "เว้นแต่ `LOCATION_ID` เป็นข้อมูลชนิด object \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['23', '6', '7', '8', '13', '37', '24', '3', '4', '14', '5', '20',\n",
       "       '19', '21', '22', '9', '11', '12', '29', '30', '38', '31', '2',\n",
       "       '32', '16', '33', '15', '36', '34', '18', '25', '39', '27', '35',\n",
       "       '40', '41', '42', '1', '28', 'LOHARU', 'NUH', 'SAFIDON', '43', '44',\n",
       "       '17'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit['LOCATION_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "พบว่า LOCATION_ID เป็นข้อมูลชนิดที่มีความหลากหลายของชนิดมากเกินไป มีทั้งที่เป็น number และ string\n",
    "\n",
    "จึงคิดว่า ไม่จำเป็นต้องใช้ สามารถดรอปทิ้งได้เลย\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audit = audit.drop(['LOCATION_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is missing value: True\n"
     ]
    }
   ],
   "source": [
    "print('is missing value:' , audit.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "พบว่า มี missing value อยู่\n",
    "\n",
    "ให้ fill missing value ด้วยค่า mean ของ column นั้นๆ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is missing value: False\n"
     ]
    }
   ],
   "source": [
    "audit = audit.fillna(audit.mean())\n",
    "\n",
    "print('is missing value:' , audit.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## การทดลอง"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### แบ่ง X และ Y เพื่อทำการ predicting\n",
    "\n",
    "1. ให้ X คือ attributes ต่างๆ ที่ทำให้ได้ผลลัพธ์ Risk (0/1)\n",
    "2. ให้ Y คือ attribute ผลลัพธ์ Risk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transforming data\n",
    "\n",
    "เนื่องจาก Y จะเป็นผลลัพธ์ Risk ซึ่งมี 2 class คือ 0 และ 1 \n",
    "\n",
    "จะทำการ label one-hot encoding เพื่อให้ output layer มี 2 node\n",
    "เช่น ข้อมูลจาก \n",
    "\n",
    "|Attribute|Risk|\n",
    "|---------|----|\n",
    "|00000    | 0  |\n",
    "|12345    | 1  |\n",
    "\n",
    "หลังการ transform จะเป็น\n",
    "\n",
    "|Attribute|Risk=0|Risk=1|\n",
    "|---------|------|------|\n",
    "|00000    |1     |0     |\n",
    "|12345    |0     |1     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sector_score  PARA_A  Score_A  Risk_A  PARA_B  Score_B  Risk_B  TOTAL  \\\n",
      "0          3.89    4.18      0.6   2.508    2.50      0.2   0.500   6.68   \n",
      "1          3.89    0.00      0.2   0.000    4.83      0.2   0.966   4.83   \n",
      "2          3.89    0.51      0.2   0.102    0.23      0.2   0.046   0.74   \n",
      "3          3.89    0.00      0.2   0.000   10.80      0.6   6.480  10.80   \n",
      "4          3.89    0.00      0.2   0.000    0.08      0.2   0.016   0.08   \n",
      "\n",
      "   numbers  Score_B.1     ...      PROB  RiSk_E  History  Prob  Risk_F  Score  \\\n",
      "0      5.0        0.2     ...       0.2     0.4        0   0.2     0.0    2.4   \n",
      "1      5.0        0.2     ...       0.2     0.4        0   0.2     0.0    2.0   \n",
      "2      5.0        0.2     ...       0.2     0.4        0   0.2     0.0    2.0   \n",
      "3      6.0        0.6     ...       0.2     0.4        0   0.2     0.0    4.4   \n",
      "4      5.0        0.2     ...       0.2     0.4        0   0.2     0.0    2.0   \n",
      "\n",
      "   Inherent_Risk  CONTROL_RISK  Detection_Risk  Audit_Risk  \n",
      "0          8.574           0.4             0.5      1.7148  \n",
      "1          2.554           0.4             0.5      0.5108  \n",
      "2          1.548           0.4             0.5      0.3096  \n",
      "3         17.530           0.4             0.5      3.5060  \n",
      "4          1.416           0.4             0.5      0.2832  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "--------\n",
      "   0  1\n",
      "0  0  1\n",
      "1  1  0\n",
      "2  1  0\n",
      "3  0  1\n",
      "4  1  0\n"
     ]
    }
   ],
   "source": [
    "X = audit.drop(['Risk'], axis = 1)\n",
    "Y = pd.get_dummies(audit['Risk'])\n",
    "\n",
    "print(X.head())\n",
    "print('--------')\n",
    "print(Y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "### สร้าง ฟังก์ชั่นต่างๆ ที่จะใช้งาน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ตัวอย่าง graph sigmoid \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1760b9769b0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA9JjS7gxYOYDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1760b622198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sigmoid function\n",
    "def sigmoid(s):\n",
    "    return 1/(1 + np.exp(-s))\n",
    "\n",
    "# sigmoid derivative function\n",
    "def sigmoid_derv(s):\n",
    "    return s * (1 - s)\n",
    "\n",
    "# cross_entropy function \n",
    "def cross_entropy(pred, real):\n",
    "    n_samples = real.shape[0]\n",
    "    res = pred - real\n",
    "    return res/n_samples\n",
    "\n",
    "# loss function\n",
    "def error(pred, real):\n",
    "    n_samples = real.shape[0]\n",
    "    logp = - np.log(pred[np.arange(n_samples), real.argmax(axis=1)])\n",
    "    loss = np.sum(logp)/n_samples\n",
    "    return loss\n",
    "\n",
    "input = np.linspace(-10, 10, 100)\n",
    "\n",
    "print('ตัวอย่าง graph sigmoid ')\n",
    "plt.plot(input, sigmoid(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### สร้าง Neural Network\n",
    "\n",
    "ในการสร้าง NN นั้น จะการกำหนด\n",
    "- input layer = X attributes\n",
    "- hidden layer\n",
    "- output layer = Y attributes\n",
    "- จำนวน node ในแต่ละ layer = จำนวน attribute\n",
    "- learning rate\n",
    "- activation function(optional) = ในที่นี้ใช้ sigmoid function\n",
    "- weight และ bias แต่ละ node\n",
    "\n",
    "#### 1. Neural Network with 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y, lr=0.5, neurons=32):\n",
    "        self.x = x\n",
    "        self.neurons = neurons\n",
    "        self.lr = lr\n",
    "        ip_dim = x.shape[1]\n",
    "        op_dim = y.shape[1]\n",
    "\n",
    "        self.w1 = np.random.randn(ip_dim, neurons)\n",
    "        self.b1 = np.zeros((1, neurons))\n",
    "        self.w2 = np.random.randn(neurons, neurons)\n",
    "        self.b2 = np.zeros((1, neurons))\n",
    "        self.w3 = np.random.randn(neurons, op_dim)\n",
    "        self.b3 = np.zeros((1, op_dim))\n",
    "        self.y = y\n",
    "\n",
    "    def feedforward(self):\n",
    "        z1 = np.dot(self.x, self.w1) + self.b1\n",
    "        self.a1 = sigmoid(z1)\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = sigmoid(z2)\n",
    "        z3 = np.dot(self.a2, self.w3) + self.b3\n",
    "        self.a3 = sigmoid(z3)\n",
    "        \n",
    "    def backprop(self, epoch):\n",
    "        loss = error(self.a3, self.y)\n",
    "#         uncomment to see loss updated\n",
    "#         if epoch % 100 == 0:\n",
    "#             print('Epoch', epoch, '/', epochs, ' Error :', loss)\n",
    "        a3_delta = cross_entropy(self.a3, self.y) # w3\n",
    "        z2_delta = np.dot(a3_delta, self.w3.T)\n",
    "        a2_delta = z2_delta * sigmoid_derv(self.a2) # w2\n",
    "        z1_delta = np.dot(a2_delta, self.w2.T)\n",
    "        a1_delta = z1_delta * sigmoid_derv(self.a1) # w1\n",
    "\n",
    "        self.w3 -= self.lr * np.dot(self.a2.T, a3_delta)\n",
    "        self.b3 -= self.lr * np.sum(a3_delta, axis=0, keepdims=True)\n",
    "        self.w2 -= self.lr * np.dot(self.a1.T, a2_delta)\n",
    "        self.b2 -= self.lr * np.sum(a2_delta, axis=0)\n",
    "        self.w1 -= self.lr * np.dot(self.x.T, a1_delta)\n",
    "        self.b1 -= self.lr * np.sum(a1_delta, axis=0)\n",
    "\n",
    "    def predict(self, data):\n",
    "        self.x = data\n",
    "        self.feedforward()\n",
    "        return self.a3.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Neural Network with 2 hidden layers\n",
    "\n",
    "คล้ายๆ กับข้างบน แต่ทำกาเพิ่ม hidden layer ขึ้นมาอีก 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork2HiddenLayers:\n",
    "    def __init__(self, x, y, lr=0.5, neurons=32):\n",
    "        self.x = x\n",
    "        self.neurons = neurons\n",
    "        self.lr = lr\n",
    "        ip_dim = x.shape[1]\n",
    "        op_dim = y.shape[1]\n",
    "\n",
    "        self.w1 = np.random.randn(ip_dim, neurons)\n",
    "        self.b1 = np.zeros((1, neurons))\n",
    "        self.w2 = np.random.randn(neurons, neurons)\n",
    "        self.b2 = np.zeros((1, neurons))\n",
    "        self.w3 = np.random.randn(neurons, neurons)\n",
    "        self.b3 = np.zeros((1, neurons))\n",
    "        self.w4 = np.random.randn(neurons, op_dim)\n",
    "        self.b4 = np.zeros((1, op_dim))\n",
    "        self.y = y\n",
    "\n",
    "    def feedforward(self):\n",
    "        z1 = np.dot(self.x, self.w1) + self.b1\n",
    "        self.a1 = sigmoid(z1)\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = sigmoid(z2)\n",
    "        z3 = np.dot(self.a2, self.w3) + self.b3\n",
    "        self.a3 = sigmoid(z3)\n",
    "        z4 = np.dot(self.a3, self.w4) + self.b4\n",
    "        self.a4 = sigmoid(z4)\n",
    "        \n",
    "    def backprop(self, epoch):\n",
    "        loss = error(self.a4, self.y)\n",
    "#         uncommented to see updated loss\n",
    "#         if epoch % 100 == 0:\n",
    "#             print('Epoch', epoch, '/', epochs, ' Error :', loss)\n",
    "        a4_delta = cross_entropy(self.a4, self.y) # w4\n",
    "        z3_delta = np.dot(a4_delta, self.w4.T)\n",
    "        a3_delta = z3_delta * sigmoid_derv(self.a3) # w3\n",
    "        z2_delta = np.dot(a3_delta, self.w3.T)\n",
    "        a2_delta = z2_delta * sigmoid_derv(self.a2) # w2\n",
    "        z1_delta = np.dot(a2_delta, self.w2.T)\n",
    "        a1_delta = z1_delta * sigmoid_derv(self.a1) # w1\n",
    "\n",
    "        self.w4 -= self.lr * np.dot(self.a3.T, a4_delta)\n",
    "        self.b4 -= self.lr * np.sum(a4_delta, axis=0, keepdims=True)\n",
    "        self.w3 -= self.lr * np.dot(self.a2.T, a3_delta)\n",
    "        self.b3 -= self.lr * np.sum(a3_delta, axis=0)\n",
    "        self.w2 -= self.lr * np.dot(self.a1.T, a2_delta)\n",
    "        self.b2 -= self.lr * np.sum(a2_delta, axis=0)\n",
    "        self.w1 -= self.lr * np.dot(self.x.T, a1_delta)\n",
    "        self.b1 -= self.lr * np.sum(a1_delta, axis=0)\n",
    "\n",
    "    def predict(self, data):\n",
    "        self.x = data\n",
    "        self.feedforward()\n",
    "        return self.a4.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fitting NN model \n",
    "\n",
    "โดยการกำหนดค่าเหล่านี้ให้แตกต่างกันเพื่อหา model ที่ดีที่สุด\n",
    "\n",
    "- no. hidden level\n",
    "- learning rate\n",
    "- no. of hidden layer node\n",
    "- epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NN (inputs,hidden_level,outputs,lr,nr):\n",
    "    if(hidden_level == 1):\n",
    "        return NeuralNetwork(inputs,outputs,lr,nr)\n",
    "    else:\n",
    "        return NeuralNetwork2HiddenLayers(inputs,outputs,lr,nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_model(model, epochs):\n",
    "    for x in range(0, epochs + 1):\n",
    "        model.feedforward()\n",
    "        model.backprop(x)\n",
    "    return model\n",
    "\n",
    "def get_model_accuracy(model, x, y):\n",
    "    acc = 0\n",
    "    for xx,yy in zip(x, y):\n",
    "        s = model.predict(xx)\n",
    "        if s == np.argmax(yy):\n",
    "            acc +=1\n",
    "    return acc/len(x)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = [100,500,1000]\n",
    "\n",
    "lrs = [0.01,0.1,0.5]\n",
    "\n",
    "neurons = [1,2,16]\n",
    "\n",
    "hidden_levels = [1,2]\n",
    "\n",
    "default_epochs = 500\n",
    "default_lr = 0.5\n",
    "default_neurons = 16\n",
    "default_level = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10 fold cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = 3.0\n",
    "\n",
    "def K_FoldCV(X, hidden_level, lr, neurons, epoch):\n",
    "    fold = 1\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(audit):\n",
    "        print('Fold:', fold, end=' ')\n",
    "        X_train, X_test = X.iloc[train_index].values, X.iloc[test_index].values\n",
    "        y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    #   create Neural Network with 1 or 2 level hidden layer, learning rate and each level hidden node size\n",
    "        model = NN(inputs = X_train/scaler, outputs= np.array(y_train), hidden_level=hidden_level, lr=lr, nr=neurons)\n",
    "\n",
    "    #   training model\n",
    "        model = training_model(model, epoch)\n",
    "\n",
    "        train_acc = get_model_accuracy(model, X_train, np.array(y_train))\n",
    "        test_acc = get_model_accuracy(model, X_test, np.array(y_test))\n",
    "\n",
    "#         print(\"Training accuracy :\", train_acc)\n",
    "#         print(\"Test accuracy :\", test_acc)\n",
    "    \n",
    "        scores.append(test_acc)\n",
    "        fold += 1\n",
    "        \n",
    "#         R2 score\n",
    "        r2 = np.mean(scores)\n",
    "        print('R2 Score: ', r2)\n",
    "    \n",
    "    print('Overall R2 Score:', r2)\n",
    "    print('\\n')\n",
    "    \n",
    "    return r2\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## การทดลอง\n",
    "\n",
    "### 1 การทดลองเพื่อทดสอบผลความถูกต้องจาก การจำแนก โดยการ preprocess ที่ต่างกัน\n",
    "\n",
    "- model0 = input data ที่มี attribute เดียว\n",
    "- model1 = input data ที่ทำการ drop ข้อมูลจำพวกการสรุปต่างๆ \n",
    "- model2 = input data ที่รวมการสรุปข้อมูลต่างๆ ไว้\n",
    "\n",
    "**fixed parameter** \n",
    "- hidden level = 1\n",
    "- learning rate = 0.5\n",
    "- no. node = 16\n",
    "- epoch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN with input X0\n",
      "Fold: 1 R2 Score:  62.8205128205\n",
      "Fold: 2 R2 Score:  62.1794871795\n",
      "Fold: 3 R2 Score:  59.8290598291\n",
      "Fold: 4 R2 Score:  58.6538461538\n",
      "Fold: 5 R2 Score:  61.2820512821\n",
      "Fold: 6 R2 Score:  61.7521367521\n",
      "Fold: 7 R2 Score:  60.7226107226\n",
      "Fold: 8 R2 Score:  62.2231934732\n",
      "Fold: 9 R2 Score:  62.9574129574\n",
      "Fold: 10 R2 Score:  62.5058275058\n",
      "Overall R2 Score: 62.5058275058\n",
      "\n",
      "\n",
      "NN with input X1\n",
      "Fold: 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tusave\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:  93.5897435897\n",
      "Fold: 2 R2 Score:  94.2307692308\n",
      "Fold: 3 R2 Score:  94.4444444444\n",
      "Fold: 4 R2 Score:  93.9102564103\n",
      "Fold: 5 R2 Score:  93.0769230769\n",
      "Fold: 6 R2 Score:  92.3076923077\n",
      "Fold: 7 R2 Score:  92.1078921079\n",
      "Fold: 8 R2 Score:  92.7697302697\n",
      "Fold: 9 R2 Score:  92.562992563\n",
      "Fold: 10 R2 Score:  92.007992008\n",
      "Overall R2 Score: 92.007992008\n",
      "\n",
      "\n",
      "NN with input X2\n",
      "Fold: 1 R2 Score:  94.8717948718\n",
      "Fold: 2 R2 Score:  97.4358974359\n",
      "Fold: 3 R2 Score:  98.2905982906\n",
      "Fold: 4 R2 Score:  98.0769230769\n",
      "Fold: 5 R2 Score:  97.9487179487\n",
      "Fold: 6 R2 Score:  97.6495726496\n",
      "Fold: 7 R2 Score:  97.0577042006\n",
      "Fold: 8 R2 Score:  97.1008158508\n",
      "Fold: 9 R2 Score:  96.8457468457\n",
      "Fold: 10 R2 Score:  96.5118215118\n",
      "Overall R2 Score: 96.5118215118\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X0 = pd.DataFrame(audit['Sector_score'])\n",
    "\n",
    "X1 = audit.drop(['TOTAL', 'Prob', 'Risk_A', 'Risk_B', 'Risk_C', 'Risk_D', 'RiSk_E', 'Risk_F',\n",
    "                 'Score', 'Inherent_Risk', 'CONTROL_RISK', 'District_Loss', 'PROB',\n",
    "       'Detection_Risk', 'Audit_Risk', 'Risk'], axis = 1)\n",
    "\n",
    "X2 = audit.drop(['Risk'], axis = 1)\n",
    "\n",
    "\n",
    "print('NN with input X0')\n",
    "model0 = K_FoldCV(X0, default_level, default_lr, default_neurons, default_epochs)\n",
    "\n",
    "print('NN with input X1')\n",
    "model1 = K_FoldCV(X1, default_level, default_lr, default_neurons, default_epochs)\n",
    "\n",
    "print('NN with input X2')\n",
    "model2 = K_FoldCV(X2, default_level, default_lr, default_neurons, default_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 การทดลองเพื่อทดสอบโครงสร้าง NN ที่เหมาะสม\n",
    "\n",
    "- model1 = NN with 1 hidden layer\n",
    "- model2 = NN with 2 hidden layers\n",
    "\n",
    "**fixed parameter** \n",
    "- learning rate = 0.5\n",
    "- no. node = 16\n",
    "- epoch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN with 1 hidden layer\n",
      "Fold: 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tusave\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:  94.8717948718\n",
      "Fold: 2 R2 Score:  96.1538461538\n",
      "Fold: 3 R2 Score:  95.7264957265\n",
      "Fold: 4 R2 Score:  95.5128205128\n",
      "Fold: 5 R2 Score:  96.4102564103\n",
      "Fold: 6 R2 Score:  97.0085470085\n",
      "Fold: 7 R2 Score:  96.879311165\n",
      "Fold: 8 R2 Score:  97.1070596071\n",
      "Fold: 9 R2 Score:  97.1398971399\n",
      "Fold: 10 R2 Score:  97.1661671662\n",
      "Overall R2 Score: 97.1661671662\n",
      "\n",
      "\n",
      "NN with 2 hidden layers\n",
      "Fold: 1 R2 Score:  97.4358974359\n",
      "Fold: 2 R2 Score:  96.7948717949\n",
      "Fold: 3 R2 Score:  95.2991452991\n",
      "Fold: 4 R2 Score:  95.1923076923\n",
      "Fold: 5 R2 Score:  95.641025641\n",
      "Fold: 6 R2 Score:  95.5128205128\n",
      "Fold: 7 R2 Score:  95.411731126\n",
      "Fold: 8 R2 Score:  95.8229270729\n",
      "Fold: 9 R2 Score:  95.8541458541\n",
      "Fold: 10 R2 Score:  96.008991009\n",
      "Overall R2 Score: 96.008991009\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('NN with 1 hidden layer')\n",
    "model1 = K_FoldCV(X, 1, default_lr, default_neurons, default_epochs)\n",
    "\n",
    "print('NN with 2 hidden layers')\n",
    "model2 = K_FoldCV(X, 2, default_lr, default_neurons, default_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 การทดลองเพื่อทดสอบ จำนวน node ที่เหมาะสม\n",
    "\n",
    "model = NN with different no. of hidden layer node\n",
    "\n",
    "nodes = [1,2,16]\n",
    "\n",
    "**fixed parameter** \n",
    "- hidden level = 1\n",
    "- learning rate = 0.5\n",
    "- epoch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN 1 hidden nodes\n",
      "Fold: 1 R2 Score: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tusave\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94.8717948718\n",
      "Fold: 2 R2 Score:  94.8717948718\n",
      "Fold: 3 R2 Score:  94.8717948718\n",
      "Fold: 4 R2 Score:  93.9102564103\n",
      "Fold: 5 R2 Score:  94.6153846154\n",
      "Fold: 6 R2 Score:  93.5897435897\n",
      "Fold: 7 R2 Score:  89.3106893107\n",
      "Fold: 8 R2 Score:  90.1598401598\n",
      "Fold: 9 R2 Score:  89.9544899545\n",
      "Fold: 10 R2 Score:  90.6993006993\n",
      "Overall R2 Score: 90.6993006993\n",
      "\n",
      "\n",
      "NN 2 hidden nodes\n",
      "Fold: 1 R2 Score:  94.8717948718\n",
      "Fold: 2 R2 Score:  94.8717948718\n",
      "Fold: 3 R2 Score:  95.2991452991\n",
      "Fold: 4 R2 Score:  95.1923076923\n",
      "Fold: 5 R2 Score:  94.1025641026\n",
      "Fold: 6 R2 Score:  94.6581196581\n",
      "Fold: 7 R2 Score:  94.4936016365\n",
      "Fold: 8 R2 Score:  94.6948884449\n",
      "Fold: 9 R2 Score:  94.7071447071\n",
      "Fold: 10 R2 Score:  94.9766899767\n",
      "Overall R2 Score: 94.9766899767\n",
      "\n",
      "\n",
      "NN 16 hidden nodes\n",
      "Fold: 1 R2 Score:  93.5897435897\n",
      "Fold: 2 R2 Score:  94.8717948718\n",
      "Fold: 3 R2 Score:  94.8717948718\n",
      "Fold: 4 R2 Score:  94.8717948718\n",
      "Fold: 5 R2 Score:  95.641025641\n",
      "Fold: 6 R2 Score:  96.1538461538\n",
      "Fold: 7 R2 Score:  96.1467104324\n",
      "Fold: 8 R2 Score:  96.1413586414\n",
      "Fold: 9 R2 Score:  96.4257964258\n",
      "Fold: 10 R2 Score:  96.2637362637\n",
      "Overall R2 Score: 96.2637362637\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('NN 1 hidden nodes')\n",
    "model1 = K_FoldCV(X, default_level, default_lr, 1, default_epochs)\n",
    "\n",
    "print('NN 2 hidden nodes')\n",
    "model1 = K_FoldCV(X, default_level, default_lr, 2, default_epochs)\n",
    "\n",
    "print('NN 16 hidden nodes')\n",
    "model2 = K_FoldCV(X, default_level, default_lr, 16, default_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 ความสัมพันธ์ระหว่างการกำหนดค่า learning rate และ จำนวน epoch\n",
    "\n",
    "model = NN with different learning rate and epoch\n",
    "\n",
    "no. epoch = [100,500,1000]\n",
    "\n",
    "learning rate = [0.01,0.1,0.5]\n",
    "\n",
    "**fixed parameter** \n",
    "- hidden level = 1\n",
    "- no. node = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN epoch = 100, lr = 0.01\n",
      "Fold: 1 R2 Score:  71.7948717949\n",
      "Fold: 2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tusave\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:  68.5897435897\n",
      "Fold: 3 R2 Score:  58.1196581197\n",
      "Fold: 4 R2 Score:  63.4615384615\n",
      "Fold: 5 R2 Score:  56.9230769231\n",
      "Fold: 6 R2 Score:  59.188034188\n",
      "Fold: 7 R2 Score:  59.8235098235\n",
      "Fold: 8 R2 Score:  64.0338827839\n",
      "Fold: 9 R2 Score:  67.1643171643\n",
      "Fold: 10 R2 Score:  66.4219114219\n",
      "Overall R2 Score: 66.4219114219\n",
      "\n",
      "\n",
      "NN epoch = 100, lr = 0.1\n",
      "Fold: 1 R2 Score:  93.5897435897\n",
      "Fold: 2 R2 Score:  92.3076923077\n",
      "Fold: 3 R2 Score:  92.735042735\n",
      "Fold: 4 R2 Score:  90.3846153846\n",
      "Fold: 5 R2 Score:  90.0\n",
      "Fold: 6 R2 Score:  89.1025641026\n",
      "Fold: 7 R2 Score:  88.9895818467\n",
      "Fold: 8 R2 Score:  90.2035464535\n",
      "Fold: 9 R2 Score:  89.9933399933\n",
      "Fold: 10 R2 Score:  90.0849150849\n",
      "Overall R2 Score: 90.0849150849\n",
      "\n",
      "\n",
      "NN epoch = 100, lr = 0.5\n",
      "Fold: 1 R2 Score:  96.1538461538\n",
      "Fold: 2 R2 Score:  98.0769230769\n",
      "Fold: 3 R2 Score:  97.4358974359\n",
      "Fold: 4 R2 Score:  96.7948717949\n",
      "Fold: 5 R2 Score:  96.9230769231\n",
      "Fold: 6 R2 Score:  96.1538461538\n",
      "Fold: 7 R2 Score:  96.1467104324\n",
      "Fold: 8 R2 Score:  96.466033966\n",
      "Fold: 9 R2 Score:  95.9928959929\n",
      "Fold: 10 R2 Score:  96.1338661339\n",
      "Overall R2 Score: 96.1338661339\n",
      "\n",
      "\n",
      "NN epoch = 500, lr = 0.01\n",
      "Fold: 1 R2 Score:  96.1538461538\n",
      "Fold: 2 R2 Score:  92.9487179487\n",
      "Fold: 3 R2 Score:  94.0170940171\n",
      "Fold: 4 R2 Score:  93.2692307692\n",
      "Fold: 5 R2 Score:  92.3076923077\n",
      "Fold: 6 R2 Score:  89.7435897436\n",
      "Fold: 7 R2 Score:  89.1679748823\n",
      "Fold: 8 R2 Score:  89.547952048\n",
      "Fold: 9 R2 Score:  89.2662892663\n",
      "Fold: 10 R2 Score:  88.3916083916\n",
      "Overall R2 Score: 88.3916083916\n",
      "\n",
      "\n",
      "NN epoch = 500, lr = 0.1\n",
      "Fold: 1 R2 Score:  97.4358974359\n",
      "Fold: 2 R2 Score:  96.1538461538\n",
      "Fold: 3 R2 Score:  97.0085470085\n",
      "Fold: 4 R2 Score:  97.4358974359\n",
      "Fold: 5 R2 Score:  95.641025641\n",
      "Fold: 6 R2 Score:  95.0854700855\n",
      "Fold: 7 R2 Score:  95.4164882736\n",
      "Fold: 8 R2 Score:  95.5024142524\n",
      "Fold: 9 R2 Score:  95.2806452806\n",
      "Fold: 10 R2 Score:  95.4928404928\n",
      "Overall R2 Score: 95.4928404928\n",
      "\n",
      "\n",
      "NN epoch = 500, lr = 0.5\n",
      "Fold: 1 R2 Score:  94.8717948718\n",
      "Fold: 2 R2 Score:  94.2307692308\n",
      "Fold: 3 R2 Score:  95.2991452991\n",
      "Fold: 4 R2 Score:  95.8333333333\n",
      "Fold: 5 R2 Score:  96.1538461538\n",
      "Fold: 6 R2 Score:  95.2991452991\n",
      "Fold: 7 R2 Score:  95.2285809429\n",
      "Fold: 8 R2 Score:  95.0133200133\n",
      "Fold: 9 R2 Score:  95.5673955674\n",
      "Fold: 10 R2 Score:  95.7509157509\n",
      "Overall R2 Score: 95.7509157509\n",
      "\n",
      "\n",
      "NN epoch = 1000, lr = 0.01\n",
      "Fold: 1 R2 Score:  93.5897435897\n",
      "Fold: 2 R2 Score:  93.5897435897\n",
      "Fold: 3 R2 Score:  93.5897435897\n",
      "Fold: 4 R2 Score:  92.9487179487\n",
      "Fold: 5 R2 Score:  92.0512820513\n",
      "Fold: 6 R2 Score:  90.5982905983\n",
      "Fold: 7 R2 Score:  90.4571618857\n",
      "Fold: 8 R2 Score:  90.8383283383\n",
      "Fold: 9 R2 Score:  90.4132904133\n",
      "Fold: 10 R2 Score:  89.9433899434\n",
      "Overall R2 Score: 89.9433899434\n",
      "\n",
      "\n",
      "NN epoch = 1000, lr = 0.1\n",
      "Fold: 1 R2 Score:  96.1538461538\n",
      "Fold: 2 R2 Score:  97.4358974359\n",
      "Fold: 3 R2 Score:  97.4358974359\n",
      "Fold: 4 R2 Score:  97.1153846154\n",
      "Fold: 5 R2 Score:  97.6923076923\n",
      "Fold: 6 R2 Score:  97.2222222222\n",
      "Fold: 7 R2 Score:  97.2479901051\n",
      "Fold: 8 R2 Score:  97.4296536797\n",
      "Fold: 9 R2 Score:  97.2823472823\n",
      "Fold: 10 R2 Score:  97.2943722944\n",
      "Overall R2 Score: 97.2943722944\n",
      "\n",
      "\n",
      "NN epoch = 1000, lr = 0.5\n",
      "Fold: 1 R2 Score:  97.4358974359\n",
      "Fold: 2 R2 Score:  98.7179487179\n",
      "Fold: 3 R2 Score:  98.7179487179\n",
      "Fold: 4 R2 Score:  98.3974358974\n",
      "Fold: 5 R2 Score:  98.2051282051\n",
      "Fold: 6 R2 Score:  98.2905982906\n",
      "Fold: 7 R2 Score:  97.9782122639\n",
      "Fold: 8 R2 Score:  98.0685980686\n",
      "Fold: 9 R2 Score:  97.8502978503\n",
      "Fold: 10 R2 Score:  97.8055278055\n",
      "Overall R2 Score: 97.8055278055\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('NN epoch = 100, lr = 0.01')\n",
    "score1 = K_FoldCV(X, default_level, 0.01, default_neurons, 100)\n",
    "print('NN epoch = 100, lr = 0.1')\n",
    "score2 = K_FoldCV(X, default_level, 0.1, default_neurons, 100)\n",
    "print('NN epoch = 100, lr = 0.5')\n",
    "score3 = K_FoldCV(X, default_level, 0.5, default_neurons, 100)\n",
    "\n",
    "print('NN epoch = 500, lr = 0.01')\n",
    "score4 = K_FoldCV(X, default_level, 0.01, default_neurons, 500)\n",
    "print('NN epoch = 500, lr = 0.1')\n",
    "score5 = K_FoldCV(X, default_level, 0.1, default_neurons, 500)\n",
    "print('NN epoch = 500, lr = 0.5')\n",
    "score6 = K_FoldCV(X, default_level, 0.5, default_neurons, 500)\n",
    "\n",
    "print('NN epoch = 1000, lr = 0.01')\n",
    "score7 = K_FoldCV(X, default_level, 0.01, default_neurons, 1000)\n",
    "print('NN epoch = 1000, lr = 0.1')\n",
    "score8 = K_FoldCV(X, default_level, 0.1, default_neurons, 1000)\n",
    "print('NN epoch = 1000, lr = 0.5')\n",
    "score9 = K_FoldCV(X, default_level, 0.5, default_neurons, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf3X5OHAt6fCmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1760b606470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lrs, [[score1,score2,score3],[score4,score5,score6],[score7,score8,score9]])\n",
    "\n",
    "plt.legend(epochs, title=\"Epoch\")\n",
    "\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('R2 score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## วิเคราะห์และสรุปผลการทดลอง"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### จากการทดลองต่างๆ ได้ผลสรุปดังนี้\n",
    "\n",
    "        การทดลองที่ 1 การทดลองเพื่อทดสอบผลความถูกต้องจาก การจำแนกโดยการ preprocess ที่ต่างกัน โดยการทำ preprocess กับ input data ของ neural network ที่ใช้ attribute ต่างๆ กันออกไป คือ 1. ใช้ attribute เดียว 2. ตัด attribute จำพวกการสรุปจากข้อมูลอื่น 3. ไม่ตัด ใช้ attribute ครบทุกตัว พบว่า 1. การใช้ attribute เดียว ได้ความแม่นยำต่ำมาก เนื่องจากไม่มีความสัมพันธ์ของ input และ output เลย 2. มีความแม่นยำมาก 3. มีความแม่นยำมากที่สุด เนื่องจาก attribute ทุกตัวถูกนำมาใช้ในการคำนวณ\n",
    "        \n",
    "        การทดลองที่ 2 การทดลองเพื่อทดสอบโครงสร้าง NN ที่เหมาะสม โดย 1. มี 1 hidden layer 2. มี 2 hidden layers โดย parameters อื่นๆ คงที่ พบว่า ความแม่นยำของ 2 hidden layers มีความแม่นยำมากกว่า 1 hidden layer เพราะมีการคำนวณเป็นขั้นตอนมากกว่าไปอีก 1 layer แต่ก็ใช้เวลาในการประมวลผลมากกว่าเช่นกัน\n",
    "        \n",
    "        การทดลองที่ 3 การทดลองเพื่อทดสอบ จำนวน node ที่เหมาะสม โดยกำหนดจำนวน node ที่แตกต่างกัน คือ 1 2 และ 16 nodes พบว่า ยิ่งจำนวน node เยอะ ยิ่งมีความแม่นยำของข้อมูลเยอะตามไปด้วย แต่จากการทดลองมีความแม่นยำที่ไม่ต่างกันมาก เนื่องจากผลลัพธ์ output มีแค่ 2 ค่า คือ 0 และ 1 ทำให้จำนวน node ไม่ค่อยมีผลมากสักเท่าไร\n",
    "        \n",
    "        การทดลองที่ 4 ความสัมพันธ์ระหว่างการกำหนดค่า learning rate และ จำนวน epoch โดยกำหนด learning rate และ epoch คือ 100 500 1000 และ 0.01 0.1 0.5 ตามลำดับ พบว่า จำนวน epoch และ learning rate มีผลกับความแม่นยำของ model neural network โดย เมื่อ epoch มากขึ้นจะทำให้ความแม่นยำมากขึ้นไปด้วย จนไปถึงระดับนึงความแม่นยำจะค่อนข้างคงที่ สำหรับ learning rate ยิ่ง learning rate มากขึ้นจะทำให้ model เรียนรู้ได้ไวขึ้น แต่หากเกินจุดๆ นึง อาจทำให้ค่าส่ายไปมา แล้วความแม่นยำจะลดลง ทั้งนี้ ทั้ง 2 ค่าที่กล่าวมา ต้องกำหนดค่าให้อยู่ในช่วงที่พอดี หากมากเกินหรือน้อยเกินไป จะทำให้ความแม่นยำลดลงอย่างเห็นได้ชัด\n",
    "        \n",
    "        สรุปผล พบว่าในการสร้าง neural network ขึ้นมา ต้องคำนึงถึงหลักการต่างๆ และ parameter ต่างๆ ที่มีส่วนเกี่ยวข้อง เพื่อความแม่นยำที่ดีที่สุด ต้องทำการทดลองเพื่อหาค่าที่เหมาะสมมากที่สุด เพื่อที่จะได้ neural network ที่ดีที่สุด"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
